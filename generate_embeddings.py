"""
Unified Embedding Generator for Images and Time-Series

This script scans the dataset generated by generate_dinov3_dataset.py,
generates Qwen3-VL embeddings for images and time-series (as text strings),
and saves each embedding as an individual FAISS index file (.index).

It does NOT stack them into a single file to avoid memory pressure.
"""

import os
import sys
import gc
from pathlib import Path
import json

import numpy as np
import pandas as pd
import torch

try:
    import faiss
except ImportError:
    print("Warning: faiss not installed. Script will fail.")
    faiss = None

# Add the Qwen3-VL-Embedding directory to sys.path so we can import 'src'
sys.path.append("/root/Qwen3-VL-Embedding")

from src.models.qwen3_vl_embedding import Qwen3VLEmbedder, is_image_path


# ============================================================================
# SETTINGS - Edit these variables to match your setup
# ============================================================================
# Ensure the working directory is set to /root/Qwen3-VL-Embedding/
os.chdir("/root/Qwen3-VL-Embedding/")

# Dataset root directory (output from generate_dinov3_dataset.py)
DATASET_ROOT = Path("/root/ohlcImageModule/dinov3_nifty50_dataset")

# Metadata CSV path
METADATA_CSV = DATASET_ROOT / "metadata" / "dataset-TRAIN.csv"

# Per-item embedding output folders
IMAGE_EMBED_DIR = DATASET_ROOT / "embeddings" / "images"
TS_EMBED_DIR = DATASET_ROOT / "embeddings" / "timeseries"

# Model to use for embedding generation
MODEL_PATH = "Qwen/Qwen3-VL-Embedding-8B"

# Batch size for processing (lower = less VRAM, slower)
BATCH_SIZE = 4


# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def load_dataset_paths(metadata_csv: Path, dataset_root: Path):
    """Load image and vector paths from metadata CSV."""
    if not metadata_csv.exists():
        raise FileNotFoundError(f"Metadata CSV not found: {metadata_csv}")

    df = pd.read_csv(metadata_csv)
    print(f"Loaded metadata: {len(df)} entries")

    # Build absolute image paths
    image_paths = []
    for _, row in df.iterrows():
        img_path = dataset_root / "images" / row['image_name']
        image_paths.append(str(img_path.absolute()))

    # Build absolute vector paths (filter successful vectors only)
    vector_paths = []
    for _, row in df.iterrows():
        if row.get('vector_status') == 'success' and pd.notna(row.get('vector_path')):
            vec_path = dataset_root / row['vector_path']
            vector_paths.append(str(vec_path.absolute()))

    print(f"Found {len(image_paths)} images, {len(vector_paths)} vectors")
    return image_paths, vector_paths, df


def load_ts_vectors_as_text(vector_paths: list) -> list:
    """Load time-series vectors from .npy files and convert to text strings."""
    if not vector_paths:
        return []

    texts = []
    for path in vector_paths:
        vec = np.load(path)
        # Convert numpy array directly to string
        text = str(vec)
        texts.append(text)

    print(f"Loaded {len(texts)} vectors as text")
    return texts


def ensure_dir(path: Path) -> None:
    """Create directory if it doesn't exist."""
    path.mkdir(parents=True, exist_ok=True)


def embedding_path_for_file(file_path: str, output_dir: Path) -> Path:
    """Create embedding path based on input file name."""
    base_name = Path(file_path).stem
    # Save as .index (FAISS index file)
    return output_dir / f"{base_name}.index"


def save_single_index(embedding: np.ndarray, output_path: Path) -> None:
    """Save a single embedding vector as a FAISS index."""
    d = embedding.shape[0]
    # Create a simple FlatL2 index for this single vector
    index = faiss.IndexFlatL2(d)
    # Reshape to (1, d) and add
    index.add(embedding.reshape(1, -1))
    # Save to disk
    faiss.write_index(index, str(output_path))


# ============================================================================
# MAIN LOGIC
# ============================================================================

def main():
    print("=" * 70)
    print("Individual FAISS Index Generator")
    print("=" * 70)
    
    if not faiss:
        print("ERROR: 'faiss' module not found. Please run: pip install faiss-cpu")
        return

    # Step 1: Load dataset paths from metadata
    print(f"\nStep 1: Loading dataset from {DATASET_ROOT}")
    image_paths, vector_paths, metadata_df = load_dataset_paths(
        METADATA_CSV, DATASET_ROOT
    )

    if not image_paths:
        print("No images found! Check DATASET_ROOT and METADATA_CSV paths.")
        return

    # Ensure output directories exist
    ensure_dir(IMAGE_EMBED_DIR)
    ensure_dir(TS_EMBED_DIR)

    # Step 2: Load the embedding model
    print(f"\nStep 2: Loading Qwen3-VL model: {MODEL_PATH}")
    model = Qwen3VLEmbedder(model_name_or_path=MODEL_PATH)
    print("Model loaded!")

    # Step 3: Generate image embeddings in batches
    print(f"\nStep 3: Generating image embeddings ({len(image_paths)} images)")
    
    pending_image_paths = []
    pending_image_embed_paths = []

    # Check which ones are already done
    for path in image_paths:
        embed_path = embedding_path_for_file(path, IMAGE_EMBED_DIR)
        if embed_path.exists():
            continue
        pending_image_paths.append(path)
        pending_image_embed_paths.append(embed_path)

    print(f"  Skipping {len(image_paths) - len(pending_image_paths)} existing image indices")

    if pending_image_paths:
        total_batches = (len(pending_image_paths) + BATCH_SIZE - 1) // BATCH_SIZE

        for batch_idx in range(total_batches):
            start_idx = batch_idx * BATCH_SIZE
            end_idx = min(start_idx + BATCH_SIZE, len(pending_image_paths))
            batch_paths = pending_image_paths[start_idx:end_idx]
            batch_embed_paths = pending_image_embed_paths[start_idx:end_idx]

            print(f"  Batch {batch_idx + 1}/{total_batches} ({len(batch_paths)} images)")
            
            # verbose logging
            print(f"    Processing: {[Path(p).name for p in batch_paths]}")

            # Format inputs
            inputs = [{"image": path} for path in batch_paths]

            # Generate embeddings
            print("    Running inference...")
            with torch.no_grad():
                embeddings = model.process(inputs).cpu().numpy().astype('float32')
            
            print("    Saving indices...")
            # Save each embedding as an individual FAISS index
            for idx, embed_path in enumerate(batch_embed_paths):
                save_single_index(embeddings[idx], embed_path)

            # Memory Cleanup
            print("    Cleaning up...")
            del embeddings
            del inputs
            torch.cuda.empty_cache()
            gc.collect()
    else:
        print("  All image embeddings already generated.")

    # Step 4: Load time-series vectors as text
    print(f"\nStep 4: Loading time-series vectors as text ({len(vector_paths)} vectors)")
    ts_texts = load_ts_vectors_as_text(vector_paths)

    if len(ts_texts) > 0:
        # Step 5: Generate text embeddings for time-series
        print(f"\nStep 5: Generating time-series embeddings ({len(ts_texts)} texts)")
        
        pending_ts_texts = []
        pending_ts_embed_paths = []

        # Check which ones are already done
        for path, text in zip(vector_paths, ts_texts):
            embed_path = embedding_path_for_file(path, TS_EMBED_DIR)
            if embed_path.exists():
                continue
            pending_ts_texts.append(text)
            pending_ts_embed_paths.append(embed_path)

        print(f"  Skipping {len(ts_texts) - len(pending_ts_texts)} existing time-series indices")

        if pending_ts_texts:
            total_ts_batches = (len(pending_ts_texts) + BATCH_SIZE - 1) // BATCH_SIZE

            for batch_idx in range(total_ts_batches):
                start_idx = batch_idx * BATCH_SIZE
                end_idx = min(start_idx + BATCH_SIZE, len(pending_ts_texts))
                batch_texts = pending_ts_texts[start_idx:end_idx]
                batch_embed_paths = pending_ts_embed_paths[start_idx:end_idx]

                print(f"  Batch {batch_idx + 1}/{total_ts_batches} ({len(batch_texts)} texts)")
                
                # verbose logging
                # print(f"    Processing texts for: {[Path(p).name for p in batch_paths_subset]}") # Need paths reference

                # Format inputs
                inputs = [{"text": text} for text in batch_texts]

                # Generate embeddings
                print("    Running inference...")
                with torch.no_grad():
                    embeddings = model.process(inputs).cpu().numpy().astype('float32')

                # Save each embedding as an individual FAISS index
                print("    Saving indices...")
                for idx, embed_path in enumerate(batch_embed_paths):
                    save_single_index(embeddings[idx], embed_path)

                # Memory Cleanup
                print("    Cleaning up...")
                del embeddings
                del inputs
                torch.cuda.empty_cache()
                gc.collect()
        else:
             print("  All time-series embeddings already generated.")
    else:
        print("  No time-series vectors found")

    # Free model memory
    del model
    torch.cuda.empty_cache()
    gc.collect()

    print("\n" + "=" * 70)
    print("Embedding generation complete!")
    print("=" * 70)
    print(f"  Individual FAISS indices saved in:")
    print(f"    - {IMAGE_EMBED_DIR}")
    print(f"    - {TS_EMBED_DIR}")
    print("  Note: No unified index file was created (per user request).")


if __name__ == "__main__":
    main()
